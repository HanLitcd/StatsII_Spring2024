knitr::opts_chunk$set(echo = TRUE)
stargazer::stargazer(glm(Sepal.length ~ Sepal.width + Species, data = iris,
family = "gaussian"), type = "html")
stargazer::stargazer(lm(Sepal.Length ~ Sepal.Width + Species, data = iris), type = "html")
stargazer::stargazer(glm(Sepal.Length ~ Sepal.Width + Species, data = iris,
family = "gaussian"), type = "html")
mtcars$am
?ecdf
plot(ecdf(rbinom(1000)))
?rbinom
plot(ecdf(rbinom(1000,1)))
rbinom(1000,1,0.5)
plot(ecdf(rbinom(1000,1,0.5)))
curve(pbinom, 0, 1)
curve(pbinom, from = 0, to = 1)
curve(pnorm, from = 0, to = 1)
curve(pbinom(10), from = 0, to = 1)
curve(pbinom(x =10), from = 0, to = 1)
?pbinom
curve(pbinom(0), from = 0, to = 1)
curve(pbinom(), expr = 0, from = 0, to = 1)
curve(pbinom, from = 0, to = 1)
curve(pbinom, from = 0, to = 1, size = 0)
?curve
plot(qbinom)
plot(qbinom, size = 0)
plot(qbinom(size = 1))
plot(pbinom(1:80, size = 80, prob = 0.2), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(1:80, size = 80, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(1, size = 1, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(1, size = 100, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(100, size = 1, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(1000, size = 1000, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(1:1000, size = 1000, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
plot(pbinom(0:1, size = 1, prob = 0.5), type = "s", lwd = 2,
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
x <- 1:10
plot(pbinom(x, size = 10, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 10, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 10, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
x <- 1:10
plot(pbinom(x, size = 10, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 10, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 10, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
x <- 1:100
plot(pbinom(x, size = 100, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 100, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 100, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
x <- 1:300
plot(pbinom(x, size = 300, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 300, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 300, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
x <- 1:100
plot(pbinom(x, size = 100, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 100, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 100, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
curve(pbinom(x, size = 100, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
curve(pbinom(1:10, size = 1, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
curve(pbinom(1:10, size = 10, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
curve(pbinom(x=1:10, size = 10, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
x <- 1:100
plot(pbinom(x, size = 100, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 100, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 100, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
x <- 1:100
plot(pbinom(x, size = 100, prob = 0.2), type = "s", col = "blue",
main = "Binomial distribution function",
xlab = "Number of successes", ylab = "F(x)")
lines(pbinom(x, size = 100, prob = 0.4), type = "s", col = "red")
lines(pbinom(x, size = 100, prob = 0.6), type = "s", col = "green")
legend("bottomright",
legend = c("0.2", "0.4", "0.6"),
col = c("blue","red","green"),
title = "probability")
unique(iris$species)
unique(iris$Species)
ls(iris)
dat <- iris
dat$set <- ifelse(iris$Species == "setosa", 1, 0)
mod1 <- lm(dat$set ~ Petal.Length + Petal.Width)
dat <- iris
dat$set <- ifelse(iris$Species == "setosa", 1, 0)
mod1 <- lm(set ~ Petal.Length + Petal.Width, data = dat)
stargazer::stargazer(mod1, type = "html")
dat$set
range(iris$Petal.Length)
range(iris$Petal.Width)
newdat <- data.frame(Petal.Length = 4.4,
Petal.Width = 1.3)
predict(mod1, newdat)
newdat <- data.frame(Petal.Length = 4.4,
Petal.Width = 2.4)
predict(mod1, newdat)
newdat <- data.frame(Petal.Length = 5.4,
Petal.Width = 2.4)
predict(mod1, newdat)
newdat <- data.frame(Petal.Length = 5.4,
Petal.Width = 2.4)
predict(mod1, newdat)
mod2 <- glm(set ~ Petal.Length + Petal.Width, data = dat,
family = "binomial")
stargazer::stargazer(mod2, type = "html")
predict(mod2, newdat)
predict(mod2, exp(newdat))
?predict
exp(predict(mod2, newdat))
options(scipen = 999)
exp(predict(mod2, newdat))
predict(mod2, newdat)
options(scipen = 999)
exp(predict(mod2, newdat))/(1+exp(predict(mod2, newdat)))
predict(mod2, newdat, type = "response")
options(scipen = 999)
exp(predict(mod2, newdat))/(1 + exp(predict(mod2, newdat)))
options(scipen = 999)
exp(predict(mod2, newdat))/1 + exp(predict(mod2, newdat))
options(scipen = 999)
(exp(predict(mod2, newdat)))/(1 + exp(predict(mod2, newdat)))
options(scipen = 999)
log_odds <- predict(mod2, newdat)
(exp(log_odds)/(1 + exp(log_odds))
options(scipen = 999)
log_odds <- predict(mod2, newdat)
(exp(log_odds))/(1 + exp(log_odds))
options(scipen = 999)
log_odds <- predict(mod2, newdat)
(exp^(log_odds))/(1 + exp^(log_odds))
?exp
options(scipen = 999)
log_odds <- predict(mod2, newdat)
exp(log_odds)/log1p(log_odds)
options(scipen = 999)
log_odds <- predict(mod2, newdat)
exp(log_odds)/1+exp(log_odds)
predict(mod2, newdat)
exp(log_odds)
?predict.glm
predict(mod2, newdat, type = "response")
predict(mod2, newdat, type = "response")
newdat2 <- data.frame(Petal.Length = 5.4,
Petal.Width = 2.4)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 3.0,
Petal.Width = 1.4)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 3.0,
Petal.Width = 1.4)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
dat
newdat2 <- data.frame(Petal.Length = 1.3,
Petal.Width = 0.3)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.6,
Petal.Width = 0.3)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.6,
Petal.Width = 0.6)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.6,
Petal.Width = 0.7)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.8,
Petal.Width = 0.7)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.9,
Petal.Width = 0.7)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 1.9,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 2.1,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 2.3,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 2.6,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 2.1,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
newdat2 <- data.frame(Petal.Length = 2.2,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
newdat2 <- data.frame(Petal.Length = 2.3,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
newdat2 <- data.frame(Petal.Length = 2.3,
Petal.Width = 0.8)
predict(mod2, newdat2, type = "response")
log_odds <- predict(mod2, newdat2)
exp(log_odds)/(1+exp(log_odds))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# Let's see how these plot
ggplot(data = dat, aes(Petal.Length, set)) +
geom_point() +
geom_smooth(method = "lm", color = "blue") +
geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "red")
# Let's see how these plot
ggplot(data = dat, aes(Petal.Length, set)) +
geom_point() +
geom_smooth(method = "lm", color = "blue") +
geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "red")
# Let's see how these plot
ggplot(data = dat, aes(Petal.Length, set)) +
geom_point() +
geom_smooth(method = "lm", color = "blue") +
geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "red")
install.packages(c("BH", "bit", "boot", "broom", "class", "cli", "collections", "colorspace", "curl", "data.table", "dbplyr", "digest", "dplyr", "DT", "emmeans", "evaluate", "FactoMineR", "fansi", "forcats", "foreign", "fs", "gert", "highr", "htmltools", "htmlwidgets", "httpgd", "httpuv", "IRkernel", "isoband", "jsonlite", "knitr", "languageserver", "lavaan", "lubridate", "markdown", "MASS", "Matrix", "nleqslv", "nlme", "pbdZMQ", "pbkrtest", "pkgbuild", "pkgdown", "pkgload", "purrr", "ragg", "Rcpp", "Rcsdp", "repr", "rmarkdown", "roxygen2", "spatial", "stringi", "styler", "survival", "testthat", "tidyr", "timechange", "tinytex", "vctrs", "vroom", "whisker", "xfun", "xgboost", "yaml"))
install.packages("giphyr")
devtools::install_github("haozhu233/giphyr")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(giphyr)
giphyr:::gif_Addin()
giphyr:::gif_Addin()
giphyr:::gif_Addin()
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# set seed so we all get same answers
set.seed(1234)
# create design matrix
# only 2 predictors, remember 1st column is 1s
X <- rnorm(100)
# define "real"/true relationship
real_beta <- 3
# create output variables
# as linear functions of covariates
# (1) binom
y_binom <- rbinom(100, 1, exp(X*real_beta)/(1+exp(X*real_beta)))
# (2) normal
y_norm <- X*real_beta + rnorm(100, 0, 0.5)
# (2) normal
y_norm <- X*real_beta + rnorm(100, 0, 0.5)
# derive our log-likelihood function for binomial distribution
binom_likelihood <- function(outcome, input, parameter) {
# calculate probability of success on each trial
p <- exp(parameter[1] + parameter[2]*input)/(1+exp(parameter[1] + parameter[2]*input))
# access probability density function (pdf) for binomial distribution
# specifically, calculate log.likelihood function
# using sum and negative since its' log, not normal likelihood function
-sum(dbinom(outcome, 1, p, log=TRUE))
}
# derive our log-likelihood function for binomial distribution
binom_likelihood <- function(outcome, input, parameter) {
# calculate probability of success on each trial
p <- exp(parameter[1] + parameter[2]*input)/(1+exp(parameter[1] + parameter[2]*input))
# access probability density function (pdf) for binomial distribution
# specifically, calculate log.likelihood function
# using sum and negative since its' log, not normal likelihood function
-sum(dbinom(outcome, 1, p, log=TRUE))
}
# optimise our log-likelihood function
# need to put in par, which are initial values for parameters to be optimized over
# we'll start with zero and 1 for intercept and beta
# using BFGS because it's a quasi-Newton method
# so similar to what we did in class, and what you'll get from glm()
results_binom <- optim(fn=binom_likelihood, outcome=y_binom, input=X, par=0:1, hessian=T, method="BFGS")
# print our estimated coefficients (intercept and beta_1)
results_binom$par
# confirm that we get the same thing in with glm()
coef(glm(y_binom~X, family=binomial))
# now do the same process to derive our log-likelihood function for normal distribution
norm_likelihood <- function(outcome, input, parameter) {
n      <- nrow(input)
k      <- ncol(input)
beta   <- parameter[1:k]
sigma2 <- parameter[k+1]^2
e      <- outcome - input%*%beta
logl   <- -.5*n*log(2*pi)-.5*n*log(sigma2) - ( (t(e) %*% e)/ (2*sigma2) )
return(-logl)
}
# show you two different ways to set up same likelihood function
norm_likelihood2 <- function(outcome, input, parameter) {
n <- ncol(input)
beta <- parameter[1:n]
sigma <- sqrt(parameter[1+n])
-sum(dnorm(outcome, input %*% beta, sigma, log=TRUE))
}
# print our estimated coefficients (intercept and beta_1)
results_norm <- optim(fn=norm_likelihood, outcome=y_norm, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
results_norm2 <- optim(fn=norm_likelihood, outcome=y_norm, input=cbind(1, X), par=c(1,1,1), hessian=T, method="BFGS")
# print our estimated coefficients (intercept and beta_1)
# get same results regardless of which log-likelihood function we use
results_norm$par; results_norm2$par
# confirm that we get the same thing in with glm()
coef(lm(y_norm~X))
set.seed(123)
# Generate 1000 Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
# Generate 1000 Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
# Function to approximate the KS p-value using the provided series formula
ks_p_value <- function(Dx) {
# Ensure D is positive to avoid division by zero
if (Dx <= 0) return(1)
# Constants for the calculation
pi_sq <- pi^2
upper_limit <- 1000
# Calculate the series sum
series_sum <- sum(sapply(1:upper_limit, function(k) {
exp(-(2*k - 1)^2 * pi_sq / (8 * Dx^2))
}))
# Calculate the p-value using the series sum
p_value <- sqrt(2*pi) / Dx * series_sum
# Ensure the p-value is within [0,1]
p_value <- min(max(p_value, 0), 1)
return(p_value)
}
p_value <- ks_p_value(D)
print(p_value)
source("~/.active-rstudio-document")
install.packages("reshape2")
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
# Plot using ggplot2
ggplot(pdf_data_melted, aes(x = x_values, y = value, color = variable)) +
geom_line() +
labs(title = "Comparison of Normal and Cauchy Distributions",
x = "Value",
y = "Density",
color = "Distribution") +
theme_minimal()
pvlaue
p_value
# Generate 1000 Cauchy random variables
data <- rcauchy(10000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
# Function to approximate the KS p-value using the provided series formula
ks_p_value <- function(Dx) {
# Ensure D is positive to avoid division by zero
if (Dx <= 0) return(1)
# Constants for the calculation
pi_sq <- pi^2
upper_limit <- 10000
# Calculate the series sum
series_sum <- sum(sapply(1:upper_limit, function(k) {
exp(-(2*k - 1)^2 * pi_sq / (8 * Dx^2))
}))
# Calculate the p-value using the series sum
p_value <- sqrt(2*pi) / Dx * series_sum
# Ensure the p-value is within [0,1]
p_value <- min(max(p_value, 0), 1)
return(p_value)
}
p_value <- ks_p_value(D)
# Generate 1000 Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
empiricalCDF
pnorm(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
source("~/Desktop/asds/stats2/StatsII_Spring2024/tutorials/tutorial02/tutorial02_MLE.R")
